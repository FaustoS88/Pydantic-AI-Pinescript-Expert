import streamlit as st
import asyncio
import os
import sys
import json
import pickle
from pathlib import Path
from dotenv import load_dotenv
from openai import AsyncOpenAI
from pydantic_ai.messages import ModelMessage, ModelRequest, UserPromptPart

# Add the parent directory to the path so we can import the agent
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

# Import the agent components
from agent import database_connect, Dependencies, pinescript_agent
from db_schema import validate_schema

# Load environment variables
load_dotenv(override=True)

# Constants
HISTORY_FILE = os.path.join(current_dir, "chat_history.pkl")

# Function to load chat history
def load_chat_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "rb") as f:
                return pickle.load(f)
        except Exception as e:
            st.error(f"Error loading chat history: {e}")
    return []

# Function to save chat history
def save_chat_history(messages):
    try:
        with open(HISTORY_FILE, "wb") as f:
            pickle.dump(messages, f)
    except Exception as e:
        st.error(f"Error saving chat history: {e}")

# Convert streamlit messages to model messages for the agent
def convert_to_model_messages(messages):
    model_messages = []
    for message in messages:
        if message["role"] == "user":
            model_messages.append(ModelRequest(parts=[UserPromptPart(content=message["content"])]))
        # Skip assistant messages as they'll be generated by the model
    return model_messages

# Page configuration
st.set_page_config(
    page_title="PineScript Expert",
    page_icon="📊",
    layout="wide",
)

# Custom CSS for styling
st.markdown("""
<style>
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
    }
    .chat-message.user {
        background-color: #e6f3ff;
    }
    .chat-message.assistant {
        background-color: #f0f2f6;
    }
    .chat-message .avatar {
        width: 20%;
    }
    .chat-message .content {
        width: 80%;
    }
    .chat-message img {
        max-width: 78px;
        max-height: 78px;
        border-radius: 50%;
        object-fit: cover;
    }
    .chat-message.user .content {
        padding-right: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state with persistent chat history
if "messages" not in st.session_state:
    st.session_state.messages = load_chat_history()

# Function to verify API key and database
async def verify_setup():
    # Check API key
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key or openai_api_key in ["YOUR_OPENAI_API_KEY", "sk-...", ""]:
        st.sidebar.error("⚠️ OpenAI API key not configured.")
        return False, None, 0
    
    # Check database
    try:
        async with database_connect(False) as pool:
            if await validate_schema(pool):
                doc_count = await pool.fetchval("SELECT COUNT(*) FROM pinescript_docs")
                return True, openai_api_key, doc_count
            else:
                st.sidebar.error("⚠️ Database schema invalid.")
                return False, openai_api_key, 0
    except Exception as e:
        st.sidebar.error(f"⚠️ Database connection error: {str(e)}")
        return False, openai_api_key, 0

# Function to process messages with history for context
async def process_query(prompt, history=[]):
    # Create clients and dependencies
    openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
    
    # Connect to database
    async with database_connect(False) as pool:
        # Create dependencies with OpenAI for embeddings
        deps = Dependencies(
            openai=openai_client,
            pool=pool,
            openrouter_api_key=openrouter_api_key,
            use_openrouter=bool(openrouter_api_key)
        )
        
        # Show a progress indicator while processing
        with st.spinner("Generating response..."):
            # Filter chat history to include only previous messages
            previous_messages = []
            for msg in history:
                if msg["role"] == "user":
                    # Create only user messages for history
                    previous_messages.append(ModelRequest(parts=[UserPromptPart(content=msg["content"])]))
                # We don't include assistant messages because they'll be regenerated
            
            # Use the agent to process the query with message history
            result = await pinescript_agent.run(
                prompt, 
                deps=deps,
                message_history=previous_messages
            )
            
            # Return the result
            return result.data.response, result.data.snippets_used

# Main title
st.title("PineScript Expert")
st.markdown("Ask questions about Pine Script programming for TradingView")

# Sidebar status
st.sidebar.title("Status")
setup_ok, api_key, doc_count = asyncio.run(verify_setup())

if setup_ok:
    st.sidebar.success(f"✅ Database connected with {doc_count} documents")
    masked_key = f"{api_key[:4]}...{api_key[-4:]}" if api_key and len(api_key) > 8 else "Not set"
    st.sidebar.success(f"✅ OpenAI API key: {masked_key}")
else:
    st.sidebar.warning("⚠️ Setup incomplete. Check errors above.")

# OpenRouter detection
openrouter_key = os.getenv("OPENROUTER_API_KEY")
if openrouter_key:
    st.sidebar.success(f"✅ Using OpenRouter for queries")
else:
    st.sidebar.info("Using OpenAI for queries (no OpenRouter key found)")

# Chat history management
if st.sidebar.button("Clear Chat History"):
    st.session_state.messages = []
    save_chat_history([])
    st.sidebar.success("Chat history cleared!")

# Example queries
st.sidebar.markdown("### Example Queries")
examples = [
    "How do I create a moving average crossover strategy?",
    "How to calculate RSI in Pine Script?",
    "What's the difference between series and simple variables?",
    "How to plot markers on my chart?",
    "Explain Pine Script arrays and matrices"
]

# Function to set the example as query
def set_example(example):
    st.session_state.messages.append({"role": "user", "content": example})
    save_chat_history(st.session_state.messages)
    st.rerun()

# Display example buttons
for i, example in enumerate(examples):
    if st.sidebar.button(f"{i+1}. {example}"[:40] + "..."):
        set_example(example)

# Display the conversation history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and "snippets" in message:
            st.caption(f"Used {message['snippets']} document references")

# User input
if prompt := st.chat_input("Ask about Pine Script"):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    save_chat_history(st.session_state.messages)
    
    # Immediately display the message
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Generate a response
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        response_placeholder.markdown("Thinking...")
        
        try:
            # Pass all previous messages for context
            previous_messages = st.session_state.messages[:-1]  # All but the current message
            response, snippets_used = asyncio.run(process_query(prompt, previous_messages))
            
            # Update the message with the full response
            response_placeholder.markdown(response)
            st.caption(f"Used {snippets_used} document references")
            
            # Save the response to history
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response, 
                "snippets": snippets_used
            })
            save_chat_history(st.session_state.messages)
        except Exception as e:
            response_placeholder.markdown(f"Error: {str(e)}")
            st.session_state.messages.append({
                "role": "assistant", 
                "content": f"Error: {str(e)}", 
                "snippets": 0
            })
            save_chat_history(st.session_state.messages)

# Handle example responses if needed
if len(st.session_state.messages) > 0 and st.session_state.messages[-1]["role"] == "user":
    # Process the last user message
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        response_placeholder.markdown("Thinking...")
        
        try:
            # Pass all previous messages for context
            previous_messages = st.session_state.messages[:-1]  # All but the current message
            current_message = st.session_state.messages[-1]["content"]
            response, snippets_used = asyncio.run(process_query(current_message, previous_messages))
            
            # Update the message with the full response
            response_placeholder.markdown(response)
            st.caption(f"Used {snippets_used} document references")
            
            # Save the response to history
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response, 
                "snippets": snippets_used
            })
            save_chat_history(st.session_state.messages)
        except Exception as e:
            response_placeholder.markdown(f"Error: {str(e)}")
            st.session_state.messages.append({
                "role": "assistant", 
                "content": f"Error: {str(e)}", 
                "snippets": 0
            })
            save_chat_history(st.session_state.messages)

# Only run the Streamlit interface when this script is executed directly
if __name__ == "__main__":
    # This will be handled by the Streamlit framework
    pass